\documentclass[12pt]{article}

%AMS-TeX packages

\usepackage{amssymb,amsmath,amsthm}
\usepackage{tikz-cd}
\usepackage{mathpartir}
% geometry (sets margin) and other useful packages
\usepackage[margin=1.25in]{geometry}
\usepackage{graphicx,ctable,booktabs}

\usepackage[sort&compress,square,comma,authoryear]{natbib}
\bibliographystyle{plainnat}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}

\newcommand{\self}{\mathrm{self}}
\newcommand{\tm}{\mathrm{Tm}}
\newcommand{\pow}{\mathscr P}
\newcommand{\sem}[1]{\llbracket#1\rrbracket}
\newcommand{\semprod}[1]{\llbracket#1\rrbracket}
\newcommand{\semccc}[1]{\llparenthesis#1\rrparenthesis}
\newcommand{\sole}{\mathrm{sole}}
\newcommand{\var}{\mathrm{var}}
\newcommand{\app}{\mathrm{app}}
\newcommand{\Un}[1]{\mathrm{Un}_{#1}}

%
%Fancy-header package to modify header/page numbering
%
\usepackage{fancyhdr}
\pagestyle{fancy}
%\addtolength{\headwidth}{\marginparsep} %these change header-rule width
%\addtolength{\headwidth}{\marginparwidth}
\lhead{Section \thesection}
\chead{}
\rhead{\thepage}
\lfoot{\small\scshape EECS 598: Category Theory}
\cfoot{}
\rfoot{\footnotesize Scribed Notes}
\renewcommand{\headrulewidth}{.3pt}
\renewcommand{\footrulewidth}{.3pt}
\setlength\voffset{-0.25in}
\setlength\textheight{648pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\title{Lecture 4: Simply Typed Lambda Calculus}
\author{Lecturer: Max S. New\\ Scribe: Alexander Bandukwala}
\date{September 8th, 2025}
\maketitle

\section{Disjunction Property}
For any set of propositional variables, but no axioms: \\
\[
\text{If } \cdot \vdash A \vee B  \text{ then either }  \cdot \vdash A \text{ or } \cdot \vdash B
\]

This is another distinguishing property of IPL from classical propositional logic, in that this is not true for classical propositional logic.  

In classical propositional logic for any propositional variable we have the proof that the law of excluded middle holds:
\[
 \cdot \vdash x \vee \neg x
\]
but we can't prove with no axioms which of the two cases is true.

This is why we say that IPL is \emph{Constructive}: when you are proving a disjunction under no hypotheses you have to explictitly prove one case or the other. While classical propositional logic provides indirect non-constructive arguments.

Note that in the above definition the context is empty. This is not generally true of IPL in a non-empty context.
e.g. $ x \vee y \vdash x \vee y$ does not give a constructive proof of $x$ or $y$.

This point of view says that maybe we should not really think of IPL as talking about truth at all, but as a stronger property of constructive proof or constructability.

\subsection{Constructive Example}
\[
\cdot \vdash \top \vee \top
\]

\subsubsection{Obvious Proofs}
\begin{mathpar}
  \inferrule*[Right=$\vee$I1]
  {
  \inferrule*[Right=$\top$I]
  {~}
  {\cdot \vdash \top}
  }
  {\cdot \vdash \top \vee \top}

  \inferrule*[Right=$\vee$I2]
  {
  \inferrule*[Right=$\top$I]
  {~}
  {\cdot \vdash \top}
  }
  {\cdot \vdash \top \vee \top}
\end{mathpar}
The above proofs give two different reasons the claim is true because you can prove the left hand side and it's true because you can prove the right hand side.

\subsubsection{Circuitous Proof}
\begin{mathpar}
  \inferrule*[Right=$\vee$E]
  {
  \inferrule*[Right=$\vee$I1]
  {
  \inferrule*[Right=$\top$I]
  {~}
  {\cdot \vdash \top}
  }
  {\cdot \vdash \top \vee \top} \\
   \inferrule*[Right=$\vee$I1]
   {\inferrule*[Right=assum]{~}{\top \vdash \top}}
   {\top \vdash \top \vee \top }
  }
  {\cdot \vdash \top \vee \top}
\end{mathpar}

This proof is not essentially different from the other two. It is indirect but still using $\vee$I1 to prove it, so it is a more complex version of the first proof.

We are going to use STLC to provide a theory of when two proofs are equivalent.

\section{Simply Typed Lambda Calculus (STLC)}
The Simply Typed Lambda Calculus is going to generalize directly IPL. The relationship is an instance of the \emph{Curry-Howard} correspondence.

STLC is one of the simplest possible functional programing languages. It has types, terms (programs), and an equational theory for reasoning about those programs.

The terms constructros of STLC correspond directly to the rules of inference in IPL:
\subsubsection{Judgments}

\[
\begin{array}{ll}
\textbf{IPL($\Sigma$)} & \textbf{STLC($\Sigma$)} \\[6pt]

\Gamma \;\; \text{ctx} & \Gamma \;\; \text{ctx *} \\[6pt]

A \;\; \text{Prop} & A \;\; \text{type} \\[6pt]

\inferrule{\mathcal{D}}{\Gamma \vdash A} &
\inferrule{\mathcal{D}}{\Gamma \vdash M : A} \\[6pt]

& \inferrule{\mathcal{D}}{\Gamma \vdash M=N : A}
\end{array}
\]

$M$ is a term summarizing the data of the derivation $\mathcal{D}$ as a syntactic object. So the proof derivation will be implicit in the structure of the term to be more concise than the proof trees. The last judgment is our judgment proving equalities.

A context has form
\[
  \Gamma = x_1:A_1, \; x_2:A_2, \; \ldots
  \quad\text{with all } x_i \text{ distinct and new variables never clash.}
\]
The distinct variable convention is called the \emph{Barendregt} convention.

\subsubsection{Types}
The types will in STLC are going to map directly to the proposition constructors in IPL.

\[
\begin{array}{ll}
\textbf{IPL} & \textbf{STLC} \\[6pt]

\top & 1 \;\; \texttt{Unit} \;\; () \;\; \texttt{Void} \\[6pt]

A \wedge B & A \times B \\[6pt]

A \supset B &
A \Rightarrow B \\[6pt]

\bot & 0 \\

A \vee B & A + B \\
x & x
\end{array}
\]

In STLC, each type connective comes with
\emph{introduction and elimination rules} (how to construct and deconstruct values),
as well as \emph{equational reasoning principles}.
The latter are divided into:
\begin{itemize}
  \item \textbf{Computational principles} (\(\beta\)-laws), which describe how programs simplify when you
        eliminate what was just introduced.
  \item \textbf{Extensionality principles} (\(\eta\)-laws), which describe when two terms
        are definitionally the same by their observable behavior.
\end{itemize}

\subsubsection{$A \times B$}
The introduction rule is the same as the IPL rule but with terms attached.

\paragraph{Introduction and elimination.}
\begin{mathpar}
  \inferrule*[Right=$\times$I]
  {\Gamma \vdash M : A \\ \Gamma \vdash N : B}
  {\Gamma \vdash (M, N) : A \times B}
\and
  \inferrule*[Right=$\times$E1]
  {\Gamma \vdash M : A \times B}
  {\Gamma \vdash \pi_1 M : A}
\and
  \inferrule*[Right=$\times$E2]
  {\Gamma \vdash M : A \times B}
  {\Gamma \vdash \pi_2 M : B}
\end{mathpar}

\paragraph{Computational principles (\(\beta\)-laws).}
\begin{mathpar}
  \inferrule*[Right=$\times\beta$1]
  {\Gamma \vdash M : A \\ \Gamma \vdash N : B }
  {\Gamma \vdash \pi_1 (M, N) = M : A}
\and
  \inferrule*[Right=$\times\beta$2]
  {\Gamma \vdash M : A \\ \Gamma \vdash N : B }
  {\Gamma \vdash \pi_2 (M, N) = N : B}
\end{mathpar}

\paragraph{Extensionality principles (\(\eta\)-laws).}
\begin{mathpar}
  \inferrule*[Right=$\times\eta$]
  {\Gamma \vdash M : A \times B }
  {\Gamma \vdash (\pi_1 M, \pi_2 M) = M : A \times B}
\and
  \inferrule*[Right=$\times$Ext]
  {\Gamma \vdash \pi_1 M = \pi_1 N : A \\ \Gamma \vdash \pi_2 M = \pi_2 N : B}
  {\Gamma \vdash M = N : A \times B}
\end{mathpar}

The extensionality principle is not for simplifying terms but used for reasoning about when two arbitrary terms of type $A \times B$ are equivalent or not. Both $\times\eta$ and $\times$Ext are equivalent using rules provided below.


\subsubsection{Equational Reasoning}
For a reasonable notion of equality we want an equivalence relation.

\begin{mathpar}
\inferrule*[Right=refl]
  {\Gamma \vdash M : A}
  {\Gamma \vdash M = M : A}

\inferrule*[Right=sym]
  {\Gamma \vdash N=M : A}
  {\Gamma \vdash M=N : A}

\inferrule*[Right=trans]
  {\Gamma \vdash M=N : A \\ \Gamma \vdash N=P : A}
  {\Gamma \vdash M=P : A}
\end{mathpar}

\emph{Congruence rules} tell us that our equivalence relation, equating different terms of the language, is a congruence with respect to all the operations. Whenever we add a new term constructor to the language we're also going to add a corresponding congruence rule to it. e.g.
\begin{mathpar}
\inferrule*[Right=$\times$ICong]
  {\Gamma \vdash M_1=M_2 : A \\ \Gamma \vdash N_1=N_2 : B}
  {\Gamma \vdash (M_1, N_1) = (M_2, N_2) : A \times B} \\

\inferrule*[Right=$\times$E1Cong]
  {\Gamma \vdash M = M^\prime : A \times B}
  {\Gamma \vdash \pi_1 M = \pi_1 M^\prime : A} 

\inferrule*[Right=$\times$E2Cong]
  {\Gamma \vdash M = M^\prime : A \times B}
  {\Gamma \vdash \pi_2 M = \pi_2 M^\prime : B} 
\end{mathpar}


\begin{mathpar}
    \inferrule*[Right=Assumption]
    {~}
    {\Gamma, A, \Delta \vdash A}

    \inferrule*[Right=Var]
    {~}
    {\Gamma, x:A, \Delta \vdash x:A} \\


    \inferrule*[Right=Subst]
    {\Gamma \vdash A \\ \Gamma, A \vdash B}
    {\Gamma \vdash B}

    \inferrule*[Right=Admissable Rule]
    {\Gamma \vdash N : A \\ \Gamma, x:A \vdash M:B}
    {\Gamma \vdash M[N/x] : B}
\end{mathpar}
where $M[N/x]$ is replacing all of the occurrences of the variable $x$ with $N$ in $M$.


\begin{mathpar}
\inferrule*[Right=SubstCong]
  {\Gamma \vdash N=N^\prime : A \\ \Gamma, x: A \vdash M = M^\prime : B}
  {\Gamma \vdash M[N/x] = M^\prime[N^\prime/x] : B}
\end{mathpar}

\subsubsection{$1$}
\begin{mathpar}
\inferrule*[Right=$1$I]
  {~}
  {\Gamma \vdash \texttt{()} : 1}

\inferrule*[Right=$1\eta$]
  {\Gamma \vdash M : 1}
  {\Gamma \vdash M = \texttt{()} : 1}

\inferrule*[Right=$1$Ext]
  {\Gamma \vdash M : 1 \\ \Gamma \vdash N : 1}
  {\Gamma \vdash M = N : 1}
\end{mathpar}
There's no elimination principles, and no congruence principles because there's no assumptions in the rule. There's also no $\beta$ rule because there's no elimination principle.

\subsubsection{$0$}
\begin{mathpar}
\inferrule*[Right=$0$E]
  {\Gamma \vdash M : 0}
  {\Gamma \vdash \texttt{case} M \{ \} : A}

\inferrule*[Right=$0$Ext]
  {\Gamma \vdash M : 0}
  {\Gamma \vdash N = P : A}

\inferrule*[Right=$0\eta$]
  {\Gamma \vdash N : 0 \\ \Gamma, x:0, \Delta \vdash M : A}
  {\Gamma,\Delta \vdash M[N/x] = \texttt{case} N \{ \}: A}

\inferrule*[Right=$0$Cong]
  {\Gamma \vdash M=N : 0}
  {\Gamma \vdash \texttt{case} M \{ \} = \texttt{case} N \{ \}: A}
\end{mathpar}
Dual to $1$ there's no introduction rule, but there is elimination.


\subsubsection{$+$}
Result from Rust, Either from Haskell.

\begin{mathpar}
\inferrule*[Right=$+$I1]
  {\Gamma \vdash M : A}
  {\Gamma \vdash \sigma_1 M : A + B}
  
\inferrule*[Right=$+$I2]
  {\Gamma \vdash M : B}
  {\Gamma \vdash \sigma_2 M : A + B}
  
\inferrule*[Right=$+$E]
  {\Gamma \vdash M : A + B \\ \Gamma, x : A \vdash N_1 : C \\ \Gamma, y:B \vdash N_2 : C}
  {\Gamma \vdash \texttt{case} M \{ \sigma_1 x. N_1 \mid \sigma_2 y. N_2 \}: C}

\inferrule*[Right=$+\beta$1]
  {\Gamma \vdash M : A + B \\ \Gamma, x : A \vdash N_1 : C \\ \Gamma, y:B \vdash N_2 : C}
  {\Gamma \vdash \texttt{case} (\sigma_1 M) \{ \sigma_1 x. N_1 \mid \sigma_2 y. N_2 \}=N_1[M/x]: C}

\inferrule*[Right=$+\beta$2]
  {\Gamma \vdash M : A + B \\ \Gamma, x : A \vdash N_1 : C \\ \Gamma, y:B \vdash N_2 : C}
  {\Gamma \vdash \texttt{case} (\sigma_2 M) \{ \sigma_1 x. N_1 \mid \sigma_2 y. N_2 \}=N_2[M/y]: C}

\inferrule*[Right=$+\eta$]
  {\Gamma,z:A+B,\Delta \vdash M : C \\ \Gamma \vdash N : A+B}
  {\Gamma \vdash M[N/z]=\texttt{case} N \{\sigma_1 x. M[\sigma_1 x/z] \mid \sigma_2 y. M[\sigma_2 y/z]\}: C}

\inferrule*[Right=$+$Ext]
  {\Gamma, x : A \vdash M[\sigma_1 x/z] = N[\sigma_1 x/z] : C \\
   \Gamma, y : B \vdash M[\sigma_2 y/z] = N[\sigma_2 y/z] : C}
  {\Gamma, z: A+B \vdash M = N : C}
\end{mathpar}

\subsubsection{$\Rightarrow$}

\begin{mathpar}
\inferrule*[Right=$\Rightarrow$I]
  {\Gamma, x: A \vdash M : B}
  {\Gamma \vdash \lambda x. M : A \Rightarrow B}

\inferrule*[Right=$\Rightarrow$E]
  {\Gamma\vdash M : A \Rightarrow B \\ \Gamma \vdash N : A}
  {\Gamma \vdash M N : B}

\inferrule*[Right=$\Rightarrow\beta$]
  {\Gamma, x: A \vdash M : B \\ \Gamma \vdash N : A}
  {\Gamma \vdash (\lambda x. M) N = M[N/x] : B}

\inferrule*[Right=$\Rightarrow\eta$]
  {\Gamma \vdash M : A \Rightarrow B}
  {\Gamma \vdash M = \lambda x. M x  : A \Rightarrow B}

\inferrule*[Right=$\Rightarrow$Ext]
  {\Gamma,x:A \vdash M x = N x : B}
  {\Gamma \vdash M = N : A \Rightarrow B}
\end{mathpar}

\subsubsection{Invertible Rules}
In IPL every type constructor had an invertible rule and that corresponded in the semantics to their definition by the universal property:

\begin{mathpar}
\mprset{fraction={===}}
    \inferrule*
    {\Gamma, A \vdash B}
    {\Gamma \vdash A \supset B}
\end{mathpar}

\[
\downarrow(A \supset B) = \{z | z \wedge A \leq B\}
\]

In STLC:


So if we have the admissable property of weakening we can invert the rule. But for STLC we also care about equality of terms.

We want this rule to be bijective.
\begin{mathpar}
    \inferrule*
    {\Gamma, x:A \vdash M : B}
    {\Gamma \vdash \lambda x. M : A \Rightarrow B}
\end{mathpar}


\begin{mathpar}
    \inferrule*[Right=$\Rightarrow$E]
    {\inferrule*[right=Weak]{\Gamma \vdash M : A \Rightarrow B}{\Gamma,x:A \vdash M : A \Rightarrow B} \\ \inferrule*[Right=Var]{~}{\Gamma, x: A \vdash x:A} }
    {\Gamma, x:A \vdash M x : B} \\
    
    \inferrule*[Right=$\Rightarrow\beta$]
    {\inferrule*[right=Weakening]{\Gamma, y : A \vdash M : B }{\Gamma, x : A, y : A \vdash M : B }\\ \inferrule*[Right=var]{~}{\Gamma, x : A \vdash x : A} }
    {\Gamma, x : A \vdash (\lambda y. M) x = M[x/y] : B} \\
\end{mathpar}

So we pick our $\beta$ and $\eta$ rules to make our rules logically invertible and actually bijective on the sets of terms.


\begin{mathpar}
    \inferrule[$\times$]{\inferrule
    {\Gamma \vdash M: A \\ \Gamma \vdash N : B}
    {\Gamma \vdash (M, N) : A \times B}}
    {\inferrule*[right=$\times\beta1$]{\Gamma \vdash \pi_1 (M,N) : A}{\Gamma \vdash \pi_1 (M,N) = M: A} \\ \inferrule*[right=$\times\beta2$]{\Gamma \vdash \pi_2 (M,N) : A}{\Gamma \vdash \pi_2 (M,N) = N: B}} \\

    \inferrule
    {\Gamma \vdash P : A \times B}
    {\inferrule*[Right=$\times\eta$]{\Gamma \vdash \pi_1 P : A \\ \Gamma \vdash \pi_2 P : B}
    {\Gamma \vdash (\pi_1 P, \pi_2 P) = P : A \times B}} \\

    \inferrule[+]
    {\Gamma, x: A \vdash M: C \\ \Gamma, y: B \vdash N: C}
    {\Gamma, z: A+B \vdash  \texttt{case} z \{\sigma_1 x. M \mid \sigma_1 y. N\}: C} \\

    \inferrule
    {\Gamma, z: A + B, \vdash P : C}
    {\Gamma, x: A \vdash P[\sigma_1 x/z] \\ \Gamma, y: B \vdash P[\sigma_2 y/z]}
\end{mathpar}

\subsubsection{Signatures}
A signature for IPL was
\[
\Sigma = (\Sigma_0, \Sigma_1)
\]
\[
\begin{aligned}
\Sigma_0 &\;\; \text{a set of propositional variables} \\
\Sigma_1 &\;\; \text{a set of axioms of the form } A_1, \ldots, A_n \implies B
\end{aligned}
\]

and we had rules

\begin{mathpar}
    \inferrule{x \in \Sigma_0}{x \text{ prop}}
    \inferrule{A_1, \ldots \implies B \in \Sigma_1}{A_1, \ldots \vdash B}
\end{mathpar}

Signatures in STLC will be of the form
\[
\Sigma = (\Sigma_0, \Sigma_1, \Sigma_2)
\]
\[
\begin{aligned}
\Sigma_0 &\;\; \text{a set of base types} \\
\Sigma_1 &\;\; \text{a set of function symbols of the form } 
              A_1, \ldots, A_n \to B \\
         &\;\; \text{where $A_1, \ldots, A_n$ is the domain and $B$ is the codomain,} \\
         &\;\; \text{together called the arity.} \\
\Sigma_2 &\;\; \text{Set of pairs } (M, N) \\
         &\;\; \Gamma \vdash M: A, \Gamma \vdash N :A \\
\end{aligned}
\]

with rules

\begin{mathpar}
    \inferrule{x \in \Sigma_0}{x \text{ type}}

    \inferrule*[Right=FunSymb]{f \in \Sigma_1(A_1, \ldots, B) \\ \Gamma \vdash M_1 : A_1 \dots}{\Gamma \vdash f(M_1, \ldots) : B} \\

    \inferrule{(M, N) \in \Sigma_2}{\Gamma \vdash M = N : A}
\end{mathpar}


Example Signature
\[
\begin{aligned}
\Sigma_0 &= X, S \\
\texttt{empty} &: \cdot \rightarrow S \\
\texttt{push} &: X, S \rightarrow S \\
\texttt{pop} &: S \rightarrow 1 + (X \times S)
\end{aligned}
\]

\[
\begin{array}{rcl}
\Sigma_2 \\
\cdot &\vdash \texttt{pop}(\texttt{emp}()) = \sigma_1 &: 1 + (X \times S) \\
x:X, s:S &\vdash \texttt{pop}(\texttt{push}(x,s))=\sigma_2(x,s) &: 1 + (X \times S)
\end{array}
\]

\end{document}
